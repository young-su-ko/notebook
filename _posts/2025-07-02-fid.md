---
layout: post
category: concepts
title: fréchet inception distance (in progress)
---

I recently watched MIT's [Introduction to Flow Matching and Diffusion Models](https://diffusion.csail.mit.edu/) course[^1]. It's made me interested in generative models and their applications in protein engineering. But before diving into generative models for proteins, I wanted to start off with something simpler, and luckily one of the course assignments is training a flow matching model on MNIST.

After training this model, I was super excited and showed my PI my generated digits. I was also showing him how, with classifier-free guidance, you can change the guidance value to get "better" images. He asked me if there's a quantitative way to measure how much "better" the images are, and I didn't have a great answer[^2]. I just assumed you go off of vibes.

But after reading some more image generation papers like Imagen[^3], I realized that Fréchet inception distance (FID)[^4] existed and was used to assess image quality (ah, of course, just evaluating on vibes is not enough). So, let's figure out what it is and how it works.

### inception score
FID was introduced in 2017[^5] to address the limitations of the Inception score (IS). IS is based on the outputs of a pretrained Inception v3 model. Let me think through each section.

>We apply the Inception model to every generated image to get the conditional label distribution $$p(y\mid \mathbf{x})$$. Images that contain meaningful objects should have a conditional label distribution $$p(y\mid \mathbf{x})$$ with low entropy.

What is this saying? $$\mathbf{x}$$ is the generated image, and $$y$$ is the class label. I know classification models will output logits, and if we softmax those logits, we'll get a vector where each element corresponds to a probability for a given class, and the sum of the vector is 1: this is our $$p(y\mid \mathbf{x})$$.

So what does it mean for $$p(y\mid \mathbf{x})$$ to have low entropy? From physics, low entropy refers to an organized state. Here, I'm guessing it means we have a clean peak in probability for one class. For example, if we had 3 classes (cat, dog, bird), a low entropy label distribution would be [0, 1, 0]. A high entropy distribution would be [0.33, 0.33, 0.33] -- this might happen because the image looks blurry and Inception can't easily classify the image, and therefore can't assign a clear label.

>Moreover, we expect the model to generate varied images, so the marginal $$\int p(y \mid \mathbf{x}=G(z)) dz$$ should have high entropy. Combining these two requirements, the metric that we propose is: $$\exp(\mathbb{E}_\mathbf{x} \text{KL}(p(y \mid \mathbf{x})\mid\mid p(y)))$$, where we exponentiate results so the values are easier to compare.

From the GAN paper, $$G$$ is the generator, so $$\mathbf{x}=G(z)$$ just refers to the generated images. From the flow matching lectures, I know when the word marginal appears, it's related to looking at the behavior of the entire dataset. The marginal is $$p(y) = \int p(y \mid \mathbf{x}=G(z))p(z)dz$$.

Using Monte Carlo integration, we can estimate the marginal distribution $$\hat{p}(y)$$.

$$
\hat{p}(y) = \frac{1}{N} \sum_{i=1}^{N} p(y \mid \mathbf{x}_i),\quad \mathbf{x}_i = G(z_i)
$$

Simply put, we average the label distribution $$p(y \mid \mathbf{x})$$ from many generated images. $$\hat{p}(y)$$ should have high entropy, meaning on average, the images are classified into a broad range of classes, and no single class dominates. This indicates the generated images are diverse.

Almost done. Now we calculate $$\text{KL}(p(y \mid \mathbf{x})\mid\mid \hat{p}(y))$$. This is the KL divergence between the conditional label distribution and the marginal label distribution.

---
{: data-content="footnotes"}
[^1]: This was a great series of lectures. The accompanying [lecture notes](https://diffusion.csail.mit.edu/docs/lecture-notes.pdf) are written very clearly. It was also very fun to go back and forth with 4o while referencing the lecture notes.
[^2]: Maybe this was covered in the lecture series, but I couldn't think of an answer on the spot.
[^3]: [Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding](https://arxiv.org/abs/2205.11487)
[^4]: Also I *just* realized the [dWJS](https://arxiv.org/pdf/2306.12360) paper's distributional conformity score is motivated by FID!! This makes me think it will be useful to study some image generation literature for protein generation.
[^5]: [GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium](https://arxiv.org/abs/1706.08500)